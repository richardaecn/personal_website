<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.40.1" />
  <meta name="author" content="Yin Cui">

  
  
  
  
  <meta name="description" content="Research Scientist">

  
  <link rel="alternate" hreflang="en-us" href="/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/yincui.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-54472398-1', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Yin Cui">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Yin Cui">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Yin Cui">
  <meta property="og:url" content="/">
  <meta property="og:title" content="Yin Cui">
  <meta property="og:description" content="Research Scientist">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2020-10-28T00:00:00&#43;00:00">
  

  

  <title>Yin Cui</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Yin Cui</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about" data-target="#about">
            
            <span>About</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#lists" data-target="#lists">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#misc" data-target="#misc">
            
            <span>Misc</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>



<span id="homepage" style="display: none"></span>


  





  
  
  
  <section id="about" class="home-section">
    <div class="container">
      



<div class="row">
  <div class="col-xs-12 col-md-4">
    <div id="profile">

      
      <div class="portrait" itemprop="image"
           style="background-image: url('/img/portrait.jpg');">
      </div>
      

      <div class="portrait-title">
        <h2 itemprop="name">Yin Cui</h2>
        <h3 itemprop="jobTitle">Research Scientist at  
          
            
            Google
            
        </h3>
        
      </div>
    </div>
  </div>

  <div class="col-xs-12 col-md-8" itemprop="description">
    <h1>About</h1>
    
    <p>Hi, I am Yin Cui (崔崟 in Chinese, pronounced as /yin tsui/), a Research Scientist at Google. Before joining Google, I received my Ph.D. in Computer Science from <a href="http://www.cornell.edu/">Cornell University</a> and <a href="https://tech.cornell.edu/">Cornell Tech</a> in 2019, advised by Professor <a href="http://blogs.cornell.edu/techfaculty/serge-belongie/">Serge Belongie</a>.
My research interests are Computer Vision and Machine Learning.</p>

    <div id="profile">
      <ul class="social-icon" aria-hidden="true">
        
        
        <li>
          <a href="mailto:richardaecn@gmail.com" target="_blank">
            <i class="fa fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://scholar.google.com/citations?user=iP5m52IAAAAJ&amp;hl=en" target="_blank">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://github.com/richardaecn" target="_blank">
            <i class="fa fa-github big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/pub/yin-cui/49/61a/5a8" target="_blank">
            <i class="fa fa-linkedin big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.facebook.com/yincui1989" target="_blank">
            <i class="fa fa-facebook big-icon"></i>
          </a>
        </li>
        
      </ul>
    </div>
  </div>

</div>

    </div>
  </section>
  

  
  
  
  <section id="lists" class="home-section">
    <div class="container">
      


<div class="row">
  <div class="col-xs-12">
    <h1>Publications</h1>
    
    

<h3 id="2020">2020</h3>

<ul>
<li><p>Rui Qian*, Tianjian Meng*, Boqing Gong, Ming-Hsuan Yang, Huisheng Wang, Serge Belongie, <strong>Yin Cui</strong>. Spatiotemporal Contrastive Video Representation Learning. <em>arXiv:2008.03800</em> [<a href="https://arxiv.org/abs/2008.03800">arXiv</a>]</p></li>

<li><p>Barret Zoph*, Golnaz Ghiasi*, Tsung-Yi Lin*, <strong>Yin Cui</strong>, Hanxiao Liu, Ekin D. Cubuk, Quoc V. Le. Rethinking Pre-training and Self-training. <em><strong>NeurIPS</strong> 2020</em> (<strong>Oral</strong>) [<a href="https://arxiv.org/abs/2006.06882">arXiv</a>] [<a href="https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/self_training">Code</a>]</p></li>

<li><p>Menglin Jia*, Mengyun Shi*, Mikhail Sirotenko*, <strong>Yin Cui</strong>*, Claire Cardie, Bharath Hariharan, Hartwig Adam, Serge Belongie. Fashionpedia: Ontology, Segmentation, and an Attribute Localization Dataset. <em><strong>ECCV</strong> 2020</em> (<strong>Oral</strong>) [<a href="https://fashionpedia.github.io/home/index.html">Website</a>] [<a href="https://arxiv.org/abs/2004.12276">arXiv</a>] [<a href="https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/fashionpedia">Code</a>] [<a href="https://www.kaggle.com/c/imaterialist-fashion-2020-fgvc7">Kaggle Challenge</a>]</p></li>

<li><p>Xianzhi Du, Tsung-Yi Lin, Pengchong Jin, <strong>Yin Cui</strong>, Mingxing Tan, Quoc V. Le, Xiaodan Song. Efficient Scale-Permuted Backbone with Learned Resource Distribution. <em><strong>ECCV</strong> 2020</em> [<a href="https://arxiv.org/abs/2010.11426">arXiv</a>]</p></li>

<li><p>Xianzhi Du, Tsung-Yi Lin, Pengchong Jin, Golnaz Ghiasi, Mingxing Tan, <strong>Yin Cui</strong>, Quoc V. Le, Xiaodan Song. SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization. <em><strong>CVPR</strong> 2020</em> [<a href="https://arxiv.org/abs/1912.05027">arXiv</a>] [<a href="https://github.com/tensorflow/tpu/tree/master/models/official/detection">Code</a>] [<a href="https://ai.googleblog.com/2020/06/spinenet-novel-architecture-for-object.html">Google AI Blog</a>]</p></li>

<li><p>Xuhong Li, Yves Grandvalet, Franck Davoine, Jingchun Cheng, <strong>Yin Cui</strong>, Hang Zhang, Serge Belongie, Yi-Hsuan Tsai, Ming-Hsuan Yang. Transfer learning in computer vision tasks: Remember where you come from. <em>Image and Vision Computing 2020</em> [<a href="https://www.sciencedirect.com/science/article/pii/S0262885619304469">Link</a>]</p></li>
</ul>

<h3 id="2019">2019</h3>

<ul>
<li><p><strong>Yin Cui</strong>. Learning from Fine-Grained and Long-Tailed Visual Data. <em>Cornell University Theses and Dissertations</em> [<a href="https://doi.org/10.7298/tgyt-3w09">Link</a>]</p></li>

<li><p><strong>Yin Cui</strong>*, Zeqi Gu*, Dhruv Mahajan, Laurens van der Maaten, Serge Belongie, Ser-Nam Lim. Measuring Dataset Granularity. <em>arXiv:1912.10154</em> [<a href="https://arxiv.org/abs/1912.10154">arXiv</a>]</p></li>

<li><p>Sheng Guo, Weilin Huang, Xiao Zhang, Prasanna Srikhanta, <strong>Yin Cui</strong>, Yuan Li, Hartwig Adam, Matthew R Scott, Serge Belongie. The iMaterialist Fashion Attribute Dataset. <em>ICCV Workshop on Computer Vision for Fashion, Art, and Design 2019</em> (<strong>Best Paper Award</strong>) [<a href="https://arxiv.org/abs/1906.05750">arXiv</a>] [<a href="https://github.com/visipedia/imat_fashion_comp">Code</a>]</p></li>

<li><p><strong>Yin Cui</strong>, Menglin Jia, Tsung-Yi Lin, Yang Song, Serge Belongie. Class-Balanced Loss Based on Effective Number of Samples. <em><strong>CVPR</strong> 2019</em> [<a href="https://arxiv.org/abs/1901.05555">arXiv</a>] [<a href="https://github.com/richardaecn/class-balanced-loss">Code</a>] [<a href="posters/CVPR19_Class-Balanced.pdf">Poster</a>]</p></li>
</ul>

<h3 id="2018">2018</h3>

<ul>
<li><p>Longqi Yang, <strong>Yin Cui</strong>, Yuan Xuan, Chenyang Wang, Serge Belongie, Deborah Estrin. Unbiased Offline Recommender Evaluation for Missing-Not-At-Random Implicit Feedback. <em>ACM Conference on Recommender Systems (<strong>RecSys</strong>) 2018</em> [<a href="papers/RecSys18.pdf">Link</a>] [<a href="https://github.com/ylongqi/unbiased-offline-recommender-evaluation">Code</a>] [<a href="slides/RecSys18.pdf">Slides</a>]</p></li>

<li><p>Guandao Yang, <strong>Yin Cui</strong>, Serge Belongie, Bharath Hariharan. Learning Single-View 3D Reconstruction with Limited Pose Supervision. <em><strong>ECCV</strong> 2018</em> [<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Guandao_Yang_A_Unified_Framework_ECCV_2018_paper.pdf">Link</a>] [<a href="https://github.com/stevenygd/3d-recon">Code</a>] [<a href="posters/ECCV18_3drecon.pdf">Poster</a>]</p></li>

<li><p><strong>Yin Cui</strong>, Yang Song, Chen Sun, Andrew Howard, Serge Belongie. Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning. <em><strong>CVPR</strong> 2018</em> [<a href="https://arxiv.org/abs/1806.06193">arXiv</a>] [<a href="https://github.com/visipedia/inat_comp/tree/master/2017">Data</a>] [<a href="https://github.com/richardaecn/cvpr18-inaturalist-transfer">Code</a>] [<a href="posters/CVPR18_FGVC.pdf">Poster</a>] [<a href="https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/1">Tensorflow Hub</a>]</p></li>

<li><p><strong>Yin Cui</strong>, Guandao Yang, Andreas Veit, Xun Huang, Serge Belongie. Learning to Evaluate Image Captioning. <em><strong>CVPR</strong> 2018</em> [<a href="http://arxiv.org/abs/1806.06422">arXiv</a>] [<a href="https://github.com/richardaecn/cvpr18-caption-eval">Code</a>] [<a href="posters/CVPR18_caption_eval.pdf">Poster</a>]</p></li>

<li><p>Grant Van Horn, Oisin Mac Aodha, Yang Song, <strong>Yin Cui</strong>, Chen Sun, Alex Shepard, Hartwig Adam, Pietro Perona, Serge Belongie. The iNaturalist Species Classification and Detection Dataset. <em><strong>CVPR</strong> 2018</em> (<strong>Spotlight</strong>) [<a href="https://arxiv.org/abs/1707.06642">arXiv</a>] [<a href="https://github.com/visipedia/inat_comp">Data</a>] [<a href="https://github.com/tensorflow/models/tree/master/research/object_detection#sep-17-2018">Tensorflow Object Detection API</a>] [<a href="https://ai.googleblog.com/2018/03/introducing-inaturalist-2018-challenge.html">Google AI Blog</a>] [<a href="https://techcrunch.com/2018/06/21/species-identifying-ai-gets-a-boost-from-images-snapped-by-citizen-naturalists/">TechCrunch</a>]</p></li>
</ul>

<h3 id="2017">2017</h3>

<ul>
<li><p><strong>Yin Cui</strong>, Feng Zhou, Jiang Wang, Xiao Liu, Yuanqing Lin, Serge Belongie. Kernel Pooling for Convolutional Neural Networks. <em><strong>CVPR</strong> 2017</em> [<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Cui_Kernel_Pooling_for_CVPR_2017_paper.pdf">Link</a>] [<a href="posters/CVPR17_FGVC.pdf">Poster</a>]</p></li>

<li><p>Cheng-Kang Hsieh, Longqi Yang, <strong>Yin Cui</strong>, Tsung-Yi Lin, Serge Belongie, Deborah Estrin. Collaborative Metric Learning. <em>International Conference on World Wide Web (<strong>WWW</strong>) 2017</em> [<a href="papers/WWW17_CML.pdf">Link</a>] [<a href="https://github.com/changun/CollMetric">Code</a>] [<a href="slides/WWW17_CML.pdf">Slides</a>]</p></li>
</ul>

<h3 id="2016">2016</h3>

<ul>
<li><strong>Yin Cui</strong>, Feng Zhou, Yuanqing Lin, Serge Belongie. Fine-grained Categorization and Dataset Bootstrapping using Deep Metric Learning with Humans in the Loop. <em><strong>CVPR</strong> 2016</em> [<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Cui_Fine-Grained_Categorization_and_CVPR_2016_paper.pdf">Link</a>] [<a href="https://arxiv.org/abs/1512.05227">arXiv</a>] [<a href="posters/CVPR16_FGVC.pdf">Poster</a>]</li>
</ul>

<h3 id="2015">2015</h3>

<ul>
<li><p>Longqi Yang, <strong>Yin Cui</strong>, Fan Zhang, John P Pollak, Serge Belongie, Deborah Estrin. PlateClick: Bootstrapping Food Preferences Through an Adaptive Visual Interface. <em>ACM International on Conference on Information and Knowledge Management (<strong>CIKM</strong>) 2015</em> [<a href="papers/CIKM15_PlateClick.pdf">Link</a>] [<a href="data/recipe9k.zip">Data</a>] [<a href="slides/CIKM15_PlateClick.pdf">Slides</a>]</p></li>

<li><p>Tsung-Yi Lin, <strong>Yin Cui</strong>, Serge Belongie, James Hays. Learning Deep Representations for Ground-to-Aerial Geolocalization. <em><strong>CVPR</strong> 2015</em> (<strong>Oral</strong>) [<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Lin_Learning_Deep_Representations_2015_CVPR_paper.pdf">Link</a>] [<a href="https://drive.google.com/folderview?id=0B6Udwolfp4WYUkhRYTNneUhXWEU&usp=sharing">Data</a>] [<a href="papers/CVPR15_Geolocalization_Abstract.pdf">Extended Abstract</a>] [<a href="posters/CVPR15_DeepGeo.pdf">Poster</a>]</p></li>
</ul>

<h3 id="2014">2014</h3>

<ul>
<li><p>Tao Chen, Felix X Yu, Jiawei Chen, <strong>Yin Cui</strong>, Yan-Ying Chen, Shih-Fu Chang. Object-based visual sentiment concept analysis and application. <em>ACM international conference on Multimedia (<strong>MM</strong>) 2014</em> [<a href="papers/ACMMM14_VisualSentiment.pdf">Link</a>]</p></li>

<li><p><strong>Yin Cui</strong>, Dong Liu, Jiawei Chen, Shih-Fu Chang. Building a large concept bank for representing events in video. <em>arXiv:1403.7591</em> [<a href="https://arxiv.org/abs/1403.7591">arXiv</a>]</p></li>

<li><p>Jiawei Chen*, <strong>Yin Cui</strong>*, Guangnan Ye, Dong Liu, Shih-Fu Chang (*equal contribution). Event-driven semantic concept discovery by exploiting weakly tagged internet images. <em>International Conference on Multimedia Retrieval (<strong>ICMR</strong>) 2014</em> [<a href="papers/ICMR14_FlickrConcept.pdf">Link</a>] [<a href="slides/ICMR14_FlickrConcept.pdf">Slides</a>]</p></li>

<li><p><strong>Yin Cui</strong>, Yongzhou Xiang, Kun Rong, Rogerio Feris, Liangliang Cao. A spatial-color layout feature for content-based galaxy image retrieval. <em>Winter Conference on Applications of Computer Vision (<strong>WACV</strong>) 2014</em> [<a href="papers/WACV14_Galaxy.pdf">Link</a>] [<a href="posters/WACV14_Galaxy.pdf">Poster</a>]</p></li>
</ul>

  </div>
</div>

    </div>
  </section>
  

  
  
  
  <section id="misc" class="home-section">
    <div class="container">
      


<div class="row">
  <div class="col-xs-12">
    <h1>Miscellaneous</h1>
    
    

<h3 id="professional-activities">Professional Activities</h3>

<ul>
<li>Organizing Committee of ImageNet and COCO Visual Recognition Workshop at ICCV 2015, ECCV 2016</li>
<li>Organizing Committee of Joint Workshop of the COCO and Places Challenges at ICCV 2017</li>
<li>Organizing Committee of Joint COCO and Mapilary Recognition Challenge Workshop at ECCV 2018, ICCV 2019</li>
<li>Organizing Committee of Joint COCO and LVIS Recognition Challenge Workshop at ECCV 2020</li>
<li>Organizing Committee of Fine-Grained Visual Categorization Workshop at CVPR 2017, CVPR 2018</li>
<li>Organizing Committee of Large-scale Scene Understanding Workshop (COCO Captioning Challenge) at CVPR 2015</li>
<li>Member of Common Visual Data Foundation (CVDF), 2016 - Present</li>
<li>Reviewer for CVPR, ICCV, ECCV, NeurIPS and ICML</li>
</ul>

<h3 id="selected-honors">Selected Honors</h3>

<ul>
<li>McMullen Fellowship (Sep 2014)</li>
<li>Edwin Howard Armstrong Memorial Award (May 2014)</li>
<li>Wei Family Private Foundation Special Scholarship (Oct 2013)</li>
<li>National Scholarship (Oct 2010)</li>
</ul>

  </div>
</div>

    </div>
  </section>
  



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2020 Yin Cui &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script id="dsq-count-scr" src="//richardaecn.disqus.com/count.js" async></script>
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>


